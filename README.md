# NeuralNetworkFromScratch
An implementation of Neural Network from scratch on mnist dataset
__________
The code i've provided is not complete like Pytorch and Tensorflow at all! It's just a simple two layer network. But i made it clear for understanding. 

You have to know only algebra and math and a little bit working with numpy library

how does the network looke like?
* 1. Forward Function ✅
* 2. Backward Function (Backpropagation) ✅
* 3. Convolution ✅
* 4. Pooling (MaxPooling) ✅
* 5. Dropout ✅
* 6. Loss (Cross-Entropy) ✅
* 7. Optimizer (SGD) ✅
    * SGD is simpler to implement
* 8. Fully Connected (Dense or Linear) ✅
* 9. Activation (ReLU & Sigmoid) ✅
__________
You can use my handwritten notes for better understanding

![NN from Scratch](https://github.com/user-attachments/assets/9ffb208a-bc2f-4d06-9a9a-7e2d4ec12ece)
